{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c4e575-a1af-4558-b088-95a62ffb8b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting ArcPy Deep Learning training (backbone unfrozen)...\n",
      "\n",
      "ðŸ§  Launching training job...\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Object: Error in executing tool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Launch Training (19 Positional Arguments, Unfrozen Backbone)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ§  Launching training job...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m arcpy\u001b[38;5;241m.\u001b[39mia\u001b[38;5;241m.\u001b[39mTrainDeepLearningModel(\n\u001b[0;32m     31\u001b[0m     training_data_path,               \u001b[38;5;66;03m# in_training_data\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     model_output_path,                \u001b[38;5;66;03m# out_model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;241m20\u001b[39m,                               \u001b[38;5;66;03m# max_epochs\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChangeDetector\u001b[39m\u001b[38;5;124m\"\u001b[39m,                 \u001b[38;5;66;03m# model_type\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;241m4\u001b[39m,                                \u001b[38;5;66;03m# batch_size\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPAM\u001b[39m\u001b[38;5;124m\"\u001b[39m},        \u001b[38;5;66;03m# model_arguments\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,                               \u001b[38;5;66;03m# learning_rate\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRESNET50\u001b[39m\u001b[38;5;124m\"\u001b[39m,                       \u001b[38;5;66;03m# backbone_model\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,                               \u001b[38;5;66;03m# pretrained_model\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;241m10\u001b[39m,                               \u001b[38;5;66;03m# validation_percent\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALID_LOSS\u001b[39m\u001b[38;5;124m\"\u001b[39m,                     \u001b[38;5;66;03m# stop_training\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNFREEZE_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m,                 \u001b[38;5;66;03m# freeze (unfrozen backbone)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEFAULT\u001b[39m\u001b[38;5;124m\"\u001b[39m,                        \u001b[38;5;66;03m# augmentation\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,                               \u001b[38;5;66;03m# augmentation_parameters\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;241m256\u001b[39m,                              \u001b[38;5;66;03m# chip_size\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,                               \u001b[38;5;66;03m# resize_to\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALL_RANDOM\u001b[39m\u001b[38;5;124m\"\u001b[39m,                     \u001b[38;5;66;03m# weight_init_scheme\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALID_LOSS\u001b[39m\u001b[38;5;124m\"\u001b[39m                      \u001b[38;5;66;03m# monitor_metric\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Polling Loop for Live Logging\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m     54\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\ia\\Functions.py:9364\u001b[0m, in \u001b[0;36mTrainDeepLearningModel\u001b[1;34m(in_folder, out_folder, max_epochs, model_type, batch_size, arguments, learning_rate, backbone_model, pretrained_model, validation_percentage, stop_training, freeze, augmentation, augmentation_parameters, chip_size, resize_to, weight_init_scheme, monitor, tensorboard)\u001b[0m\n\u001b[0;32m   9341\u001b[0m     result \u001b[38;5;241m=\u001b[39m arcpy\u001b[38;5;241m.\u001b[39mgp\u001b[38;5;241m.\u001b[39mTrainDeepLearningModel_ia(\n\u001b[0;32m   9342\u001b[0m         in_folder,\n\u001b[0;32m   9343\u001b[0m         out_folder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9360\u001b[0m         tensorboard,\n\u001b[0;32m   9361\u001b[0m     )\n\u001b[0;32m   9362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arcpy\u001b[38;5;241m.\u001b[39mconvertArcObjectToPythonObject(result)\n\u001b[1;32m-> 9364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Wrapper(\n\u001b[0;32m   9365\u001b[0m     in_folder,\n\u001b[0;32m   9366\u001b[0m     out_folder,\n\u001b[0;32m   9367\u001b[0m     max_epochs,\n\u001b[0;32m   9368\u001b[0m     model_type,\n\u001b[0;32m   9369\u001b[0m     batch_size,\n\u001b[0;32m   9370\u001b[0m     arguments,\n\u001b[0;32m   9371\u001b[0m     learning_rate,\n\u001b[0;32m   9372\u001b[0m     backbone_model,\n\u001b[0;32m   9373\u001b[0m     pretrained_model,\n\u001b[0;32m   9374\u001b[0m     validation_percentage,\n\u001b[0;32m   9375\u001b[0m     stop_training,\n\u001b[0;32m   9376\u001b[0m     freeze,\n\u001b[0;32m   9377\u001b[0m     augmentation,\n\u001b[0;32m   9378\u001b[0m     augmentation_parameters,\n\u001b[0;32m   9379\u001b[0m     chip_size,\n\u001b[0;32m   9380\u001b[0m     resize_to,\n\u001b[0;32m   9381\u001b[0m     weight_init_scheme,\n\u001b[0;32m   9382\u001b[0m     monitor,\n\u001b[0;32m   9383\u001b[0m     tensorboard,\n\u001b[0;32m   9384\u001b[0m )\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\sa\\Utils.py:45\u001b[0m, in \u001b[0;36mStateSwapper.__call__.<locals>.swapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     result \u001b[38;5;241m=\u001b[39m wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Reset the geoprocessor state to the original setting.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Whatever the result of calling the wrapper function, this\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# code will run.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     gp\u001b[38;5;241m.\u001b[39m_gp\u001b[38;5;241m.\u001b[39mAddOutputsToMap \u001b[38;5;241m=\u001b[39m addToResultState\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\ia\\Functions.py:9341\u001b[0m, in \u001b[0;36mTrainDeepLearningModel.<locals>.Wrapper\u001b[1;34m(in_folder, out_folder, max_epochs, model_type, batch_size, arguments, learning_rate, backbone_model, pretrained_model, validation_percentage, stop_training, freeze, augmentation, augmentation_parameters, chip_size, resize_to, weight_init_scheme, monitor, tensorboard)\u001b[0m\n\u001b[0;32m   9319\u001b[0m \u001b[38;5;129m@Utils\u001b[39m\u001b[38;5;241m.\u001b[39mStateSwapper(Utils\u001b[38;5;241m.\u001b[39mStateSwapper\u001b[38;5;241m.\u001b[39mNoSingleRasterResult)\n\u001b[0;32m   9320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mWrapper\u001b[39m(\n\u001b[0;32m   9321\u001b[0m     in_folder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9339\u001b[0m     tensorboard,\n\u001b[0;32m   9340\u001b[0m ):\n\u001b[1;32m-> 9341\u001b[0m     result \u001b[38;5;241m=\u001b[39m arcpy\u001b[38;5;241m.\u001b[39mgp\u001b[38;5;241m.\u001b[39mTrainDeepLearningModel_ia(\n\u001b[0;32m   9342\u001b[0m         in_folder,\n\u001b[0;32m   9343\u001b[0m         out_folder,\n\u001b[0;32m   9344\u001b[0m         max_epochs,\n\u001b[0;32m   9345\u001b[0m         model_type,\n\u001b[0;32m   9346\u001b[0m         batch_size,\n\u001b[0;32m   9347\u001b[0m         arguments,\n\u001b[0;32m   9348\u001b[0m         learning_rate,\n\u001b[0;32m   9349\u001b[0m         backbone_model,\n\u001b[0;32m   9350\u001b[0m         pretrained_model,\n\u001b[0;32m   9351\u001b[0m         validation_percentage,\n\u001b[0;32m   9352\u001b[0m         stop_training,\n\u001b[0;32m   9353\u001b[0m         freeze,\n\u001b[0;32m   9354\u001b[0m         augmentation,\n\u001b[0;32m   9355\u001b[0m         augmentation_parameters,\n\u001b[0;32m   9356\u001b[0m         chip_size,\n\u001b[0;32m   9357\u001b[0m         resize_to,\n\u001b[0;32m   9358\u001b[0m         weight_init_scheme,\n\u001b[0;32m   9359\u001b[0m         monitor,\n\u001b[0;32m   9360\u001b[0m         tensorboard,\n\u001b[0;32m   9361\u001b[0m     )\n\u001b[0;32m   9362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arcpy\u001b[38;5;241m.\u001b[39mconvertArcObjectToPythonObject(result)\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py:533\u001b[0m, in \u001b[0;36mGeoprocessor.__getattr__.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    531\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gp, attr)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(val):\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: val(\u001b[38;5;241m*\u001b[39mgp_fixargs(args, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convertArcObjectToPythonObject(val)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Object: Error in executing tool"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# -----------------------------\n",
    "# Environment Setup\n",
    "# -----------------------------\n",
    "arcpy.env.overwriteOutput = True\n",
    "print(\"ðŸš€ Starting ArcPy Deep Learning training (robust, unfrozen backbone)...\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "training_data_path = r\"C:\\Users\\ss2596\\Documents\\njoko training\\hansen_2022_2024_fullband\"\n",
    "model_output_path = r\"C:\\Users\\ss2596\\Documents\\Njoko_model\\hansen_2022_2024_FullBand_DLmodel\"\n",
    "os.makedirs(model_output_path, exist_ok=True)\n",
    "\n",
    "metrics_file = os.path.join(model_output_path, \"training_metrics.csv\")\n",
    "if not os.path.exists(metrics_file):\n",
    "    with open(metrics_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"epoch\", \"messages\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Data Sanity Checks\n",
    "# -----------------------------\n",
    "images_path = os.path.join(training_data_path, \"images\")\n",
    "labels_path = os.path.join(training_data_path, \"labels\")\n",
    "\n",
    "num_images = len(os.listdir(images_path)) if os.path.exists(images_path) else 0\n",
    "num_labels = len(os.listdir(labels_path)) if os.path.exists(labels_path) else 0\n",
    "\n",
    "print(f\"Found {num_images} images and {num_labels} labels in the training folder.\")\n",
    "\n",
    "if num_images == 0 or num_labels == 0:\n",
    "    raise RuntimeError(\"Training folder is missing images or labels. Check your folder structure!\")\n",
    "\n",
    "# -----------------------------\n",
    "# Training Parameters\n",
    "# -----------------------------\n",
    "max_epochs = 20\n",
    "batch_size = 4           # Reduced batch size for memory safety\n",
    "chip_size = 128          # Smaller chip size to reduce memory usage\n",
    "model_type = \"ChangeDetector\"\n",
    "backbone_model = \"RESNET50\"\n",
    "\n",
    "# -----------------------------\n",
    "# Launch Training\n",
    "# -----------------------------\n",
    "print(\"ðŸ§  Launching training job...\\n\")\n",
    "\n",
    "result = arcpy.ia.TrainDeepLearningModel(\n",
    "    training_data_path,               # in_training_data\n",
    "    model_output_path,                # out_model\n",
    "    max_epochs,                       # max_epochs\n",
    "    model_type,                        # model_type\n",
    "    batch_size,                        # batch_size\n",
    "    {\"attention_type\": \"PAM\"},         # model_arguments\n",
    "    \"\",                                # learning_rate\n",
    "    backbone_model,                     # backbone_model\n",
    "    \"\",                                 # pretrained_model\n",
    "    10,                                 # validation_percent\n",
    "    \"VALID_LOSS\",                       # stop_training\n",
    "    \"UNFREEZE_MODEL\",                   # freeze (unfrozen backbone)\n",
    "    \"DEFAULT\",                           # augmentation\n",
    "    \"\",                                  # augmentation_parameters\n",
    "    chip_size,                           # chip_size\n",
    "    \"\",                                  # resize_to\n",
    "    \"ALL_RANDOM\",                        # weight_init_scheme\n",
    "    \"VALID_LOSS\"                         # monitor_metric\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Polling Loop for Live Logging\n",
    "# -----------------------------\n",
    "epoch = 0\n",
    "while result.status < 4:  # 4 = Succeeded/Failed\n",
    "    messages = result.getMessages(0)\n",
    "    print(messages, flush=True)\n",
    "\n",
    "    # Save messages to CSV per poll\n",
    "    epoch += 1\n",
    "    with open(metrics_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch, messages.strip()])\n",
    "\n",
    "    time.sleep(30)  # Wait before next check\n",
    "\n",
    "# -----------------------------\n",
    "# Final Messages\n",
    "# -----------------------------\n",
    "print(\"\\nðŸ“Š Final Training Messages:\\n\")\n",
    "print(result.getMessages())\n",
    "\n",
    "print(\"\\nâœ… Training completed.\")\n",
    "print(f\"Checkpoints and logs saved in: {model_output_path}\")\n",
    "print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a6844-1132-4d87-9680-118dc87724f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
